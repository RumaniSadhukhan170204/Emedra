import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
import pickle
import os

# âœ… Load dataset
data = pd.read_csv("datasets/Heart_Disease_Prediction.csv")

# âœ… Drop unwanted index/Unnamed columns
data = data.loc[:, ~data.columns.str.contains('^Unnamed', case=False)]
if 'index' in data.columns:
    data = data.drop(columns=['index'])

# âœ… Encode target if necessary
if 'Heart Disease' in data.columns:
    data['Heart Disease'] = data['Heart Disease'].map({'Absence': 0, 'Presence': 1})

# âœ… Separate features & labels
X = data.drop('Heart Disease', axis=1)
y = data['Heart Disease']

print(f"âœ… Training on {X.shape[1]} features: {list(X.columns)}")

# âœ… Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# âœ… Create pipeline (scaler + model)
model = Pipeline([
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))
])

# âœ… Train model
model.fit(X_train, y_train)

# âœ… Save trained model
os.makedirs("model", exist_ok=True)
pickle.dump(model, open("model/heart_model.pkl", "wb"))

print("ðŸŽ¯ Model retrained successfully and saved to 'model/heart_model.pkl'")
